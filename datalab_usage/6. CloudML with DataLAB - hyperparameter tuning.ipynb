{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CloudML with DataLAB Part. 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello. I'm back!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session, we well learn about Hyperparameter Tuning on CloudML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you designed a small model, It's fine. You can tune its hyperparameter simpley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you don't need to use the CloudML in that case. It's enough to run the model in local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large and huge model requires a lot of hyperparameters and it's really hard to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do it autometically if you use Hyperparameter Tuning function in CloudML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop wasting your time! It's your time for sleep!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's simple code to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./model/hptuning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./model/hptuning.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn import Experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn import Estimator\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# all the function would be retured as function type\n",
    "# so I also define the train_input function inside of train_input_fn function \n",
    "# that returns the trian_input as function type\n",
    "def train_input_fn(args):\n",
    "    def train_input():\n",
    "        # genertate the train data (10000, 10) and label data (10000, 1)\n",
    "        data = []\n",
    "        label = []\n",
    "        for i in range(100):\n",
    "            if i % 2 == 0:\n",
    "                # label 1 at increasing data \n",
    "                data.append([i for i in range(10)])\n",
    "                label.append([1])\n",
    "            else:\n",
    "                # label 0 at decreasing data\n",
    "                data.append([9-i for i in range(10)])\n",
    "                label.append([0])\n",
    "\n",
    "        return tf.constant(data, tf.float32), tf.constant(label, tf.float32)\n",
    "    return train_input\n",
    "\n",
    "# your model whatever you want\n",
    "# you can see the input arguments of function pair\n",
    "# I set the input argument of args which is got from shell input to model_fn input\n",
    "# so I feel free to use it in the function\n",
    "# and 3 arguments are in the model\n",
    "# It's to be called with 3 arguments by experiment object \n",
    "def model_fn(args):\n",
    "    def model(data, label, mode):\n",
    "        metric = {}\n",
    "        steps = 0\n",
    "        # Build the model here.\n",
    "        # hidden1 and hidden2 from args is to be a parameter which will be tuned\n",
    "        layer1 = tf.layers.dense(data, 10, name=\"layer1\")\n",
    "        layer2 = tf.layers.dense(layer1, args.hidden1, name=\"layer2\")\n",
    "        layer3 = tf.layers.dense(layer2, args.hidden2, name=\"layer3\")\n",
    "        logits = tf.layers.dense(layer3, 1, name=\"logits\")\n",
    "\n",
    "        # build the graph following these case by case\n",
    "        if mode == ModeKeys.INFER:\n",
    "            metric['prediction'] = tf.argmax(tf.nn.sigmoid(logits), 1)\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = tf.losses.sigmoid_cross_entropy(label, logits)\n",
    "            metric['loss'] = loss\n",
    "\n",
    "        if mode == ModeKeys.TRAIN:\n",
    "            global_step = tf.contrib.framework.get_global_step()\n",
    "            train = tf.train.GradientDescentOptimizer(0.00001).minimize(loss, global_step)\n",
    "        else:\n",
    "            train = None\n",
    "\n",
    "        if mode == ModeKeys.EVAL:\n",
    "            prediction = tf.nn.sigmoid(logits)\n",
    "            accuracy = tf.contrib.metrics.accuracy(tf.cast(tf.round(prediction), tf.int32), tf.cast(label, tf.int32))\n",
    "            metric['accuracy'] = accuracy\n",
    "            # This line is for the hyperparameter tuning\n",
    "            # the cloudml always checks the summaries\n",
    "            # so you just add summary like this then cloudML would see it \n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        return metric, loss, train\n",
    "    return model\n",
    "\n",
    "# The experiment function would designed simpley like below\n",
    "def experiment_fn(args):\n",
    "    print(\"exp:\", args)\n",
    "    def experiment(output_dir):\n",
    "        env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "        taskInfo = env.get('task')\n",
    "        if taskInfo:\n",
    "            trial = taskInfo.get('trial', '')\n",
    "            if trial:\n",
    "                output_dir = os.path.join(output_dir, trial)\n",
    "            \n",
    "        return tf.contrib.learn.Experiment(\n",
    "            estimator=Estimator(\n",
    "                model_fn=model_fn(args),\n",
    "                model_dir=output_dir\n",
    "            ),\n",
    "            train_input_fn=train_input_fn(args),\n",
    "            eval_input_fn=train_input_fn(args),\n",
    "            train_steps=10,\n",
    "            eval_steps=5\n",
    "        )\n",
    "    return experiment\n",
    "\n",
    "# Add the argument \"hidden1\" and \"hidden2\" \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Training arguments\n",
    "    parser.add_argument(\n",
    "        '--hidden1',\n",
    "        type=int,\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--hidden2',\n",
    "        type=int,\n",
    "        required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output-dir',\n",
    "        required=True\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    output_dir = args.output_dir\n",
    "\n",
    "    learn_runner.run(experiment_fn(args), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for errors and write this file below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is key-point of this session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameterMetricTag must be same as summary name you added upon the code above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And parameterName is the arguments you set. Of course both names are same also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please care for the indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./model/hpconfig.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./model/hpconfig.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    hyperparameterMetricTag: accuracy\n",
    "    maxTrials: 4\n",
    "    maxParallelTrials: 2\n",
    "    params:\n",
    "      - parameterName: hidden1\n",
    "        type: INTEGER\n",
    "        minValue: 1\n",
    "        maxValue: 10\n",
    "        scaleType: UNIT_LINEAR_SCALE\n",
    "      - parameterName: hidden2\n",
    "        type: INTEGER\n",
    "        minValue: 1\n",
    "        maxValue: 10\n",
    "        scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if done until right here, run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: simple_model_20170614_225919\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [simple_model_20170614_225919] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe simple_model_20170614_225919\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs simple_model_20170614_225919\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "PROJECT_ID=tensorflowprojects\n",
    "BUCKET=\"gs://${PROJECT_ID}-mlengine\"\n",
    "JOB_NAME=simple_model_$(date +%Y%m%d_%H%M%S)\n",
    "PACKAGE_PATH=$(pwd)/model\n",
    "MODULE_NAME=model.hptuning\n",
    "STAGING_BUCKET=${BUCKET}\n",
    "JOB_DIR=${BUCKET}/${JOB_NAME}\n",
    "OUTPUT=${BUCKET}/${JOB_NAME}\n",
    "REGION=europe-west1\n",
    "SCALE_TIER=BASIC_GPU\n",
    "CONFIG=${PACKAGE_PATH}/hpconfig.yaml\n",
    "\n",
    "# Submit job with these settings\n",
    "gcloud ml-engine jobs submit training $JOB_NAME \\\n",
    "--package-path=$PACKAGE_PATH \\\n",
    "--module-name=$MODULE_NAME \\\n",
    "--staging-bucket=$STAGING_BUCKET \\\n",
    "--scale-tier=$SCALE_TIER \\\n",
    "--region=$REGION \\\n",
    "--config=$CONFIG \\\n",
    "-- \\\n",
    "--output-dir=$OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see whether it runs as hyperparameter tuning job through \"describe\" command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2017-06-14T22:54:12Z'\r\n",
      "jobId: simple_model_20170614_225410\r\n",
      "startTime: '2017-06-14T22:54:22Z'\r\n",
      "state: RUNNING\r\n",
      "trainingInput:\r\n",
      "  args:\r\n",
      "  - --output-dir=gs://tensorflowprojects-mlengine/simple_model_20170614_225410\r\n",
      "  hyperparameters:\r\n",
      "    goal: MAXIMIZE\r\n",
      "    hyperparameterMetricTag: accuracy\r\n",
      "    maxParallelTrials: 2\r\n",
      "    maxTrials: 4\r\n",
      "    params:\r\n",
      "    - maxValue: 10.0\r\n",
      "      minValue: 1.0\r\n",
      "      parameterName: hidden1\r\n",
      "      scaleType: UNIT_LINEAR_SCALE\r\n",
      "      type: INTEGER\r\n",
      "    - maxValue: 10.0\r\n",
      "      minValue: 1.0\r\n",
      "      parameterName: hidden2\r\n",
      "      scaleType: UNIT_LINEAR_SCALE\r\n",
      "      type: INTEGER\r\n",
      "  jobDir: gs://tensorflowprojects-mlengine/simple_model_20170614_225410\r\n",
      "  packageUris:\r\n",
      "  - gs://tensorflowprojects-mlengine/simple_model_20170614_225410/3e80309342f8620a3597d16bb82c0c3ee9f3773134792e64afc4e8f22c1b77aa/model-0.0.0.tar.gz\r\n",
      "  pythonModule: model.hptuning\r\n",
      "  region: europe-west1\r\n",
      "  scaleTier: BASIC_GPU\r\n",
      "trainingOutput:\r\n",
      "  isHyperparameterTuningJob: true\r\n",
      "\r\n",
      "View job in the Cloud Console at:\r\n",
      "https://console.cloud.google.com/ml/jobs/simple_model_20170614_225410?project=tensorflowprojects\r\n",
      "\r\n",
      "View logs at:\r\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fsimple_model_20170614_225410&project=tensorflowprojects\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs describe simple_model_20170614_225410"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Easy isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you to be help! thanks for reading a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
